{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-27T05:38:50.848570100Z",
     "start_time": "2023-09-27T05:38:50.789725800Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../pytorch/data/training.txt\", sep=\"\\t\")\n",
    "valid_df = pd.read_csv(\"../pytorch/data/validing.txt\", sep=\"\\t\")\n",
    "test_df = pd.read_csv(\"../pytorch/data/testing.txt\", sep=\"\\t\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T05:38:50.935750900Z",
     "start_time": "2023-09-27T05:38:50.797024100Z"
    }
   },
   "id": "540ad864ded6e764"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=0.1, random_state=500)\n",
    "valid_df = valid_df.sample(frac=0.1, random_state=500)\n",
    "test_df = test_df.sample(frac=0.1, random_state=500)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T05:38:50.953118900Z",
     "start_time": "2023-09-27T05:38:50.935750900Z"
    }
   },
   "id": "ec2c70f935167cae"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.iloc[idx, 1]\n",
    "        label = self.df.iloc[idx, 2]\n",
    "        return text, label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T05:38:50.963068300Z",
     "start_time": "2023-09-27T05:38:50.950864600Z"
    }
   },
   "id": "42775dd43db74f3f"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "valid_dataset = Dataset(valid_df)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "test_dataset = Dataset(test_df)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=True, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T05:38:50.999761700Z",
     "start_time": "2023-09-27T05:38:50.959047900Z"
    }
   },
   "id": "c967ebbc8161af6"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T05:38:56.271087200Z",
     "start_time": "2023-09-27T05:38:50.969320600Z"
    }
   },
   "id": "de3dd2aeb640d504"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def save_checkpoint(save_path, model, valid_loss):\n",
    "    if not save_path:\n",
    "        return\n",
    "    state_dict = {\"model_state_dict\" : model.state_dict(), \"valid_loss\" : valid_loss}\n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f\"Model saved to ==> {save_path}\")\n",
    "    \n",
    "def load_checkpoint(load_path, model):\n",
    "    if not load_path:\n",
    "        return \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f\"Model loaded from <== {load_path}\")\n",
    "    model.load_state_dict(state_dict[\"model_state_dict\"])\n",
    "    return state_dict[\"valid_loss\"]\n",
    "\n",
    "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
    "    if not save_path:\n",
    "        return \n",
    "    state_dict = {\"train_loss_list\" : train_loss_list,\n",
    "                  \"valid_loss_list\" : valid_loss_list,\n",
    "                  \"test_loss_list\" : global_steps_list}\n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f\"Model saved to ==> {save_path}\")\n",
    "    \n",
    "def load_metrics(load_path):\n",
    "    if not load_path:\n",
    "        return \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f\"Model loaded from <== {load_path}\")\n",
    "    return state_dict[\"train_loss_list\"], state_dict[\"valid_loss_list\"], state_dict[\"global_steps_list\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T05:38:56.281884900Z",
     "start_time": "2023-09-27T05:38:56.272400800Z"
    }
   },
   "id": "769a5ff59a1d4b79"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion=nn.BCELoss(), num_epochs=5, eval_every=len(train_loader) // 2, best_valid_loss=float(\"Inf\")):\n",
    "    total_correct = 0.0\n",
    "    total_len = 0.0\n",
    "    running_loss = 0.0\n",
    "    valid_running_loss = 0.0\n",
    "    global_step = 0\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    global_steps_list = []\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for text, label in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "            padded_list = [e + [0] * (512 - len(e)) for e in encoded_list]\n",
    "            sample = torch.tensor(padded_list)\n",
    "            sample, label = sample.to(device), label.to(device)\n",
    "            labels = torch.tensor(label)\n",
    "            outputs = model(sample, labels=labels)\n",
    "            loss, logits = outputs\n",
    "            \n",
    "            pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "            correct = pred.eq(labels)\n",
    "            total_correct += correct.sum().item()\n",
    "            total_len += len(labels)\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            global_step += 1\n",
    "            \n",
    "            if global_step % eval_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for text, label in valid_loader:\n",
    "                        encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "                        padded_list = [e + [0] * (512 - len(e)) for e in encoded_list]\n",
    "                        sample = torch.tensor(padded_list)\n",
    "                        sample, label = sample.to(device), label.to(device)\n",
    "                        labels = torch.tensor(label)\n",
    "                        outputs = model(sample, labels=labels)\n",
    "                        loss, logits = outputs\n",
    "                        valid_running_loss += loss.item()\n",
    "                        \n",
    "                average_train_loss = running_loss / eval_every\n",
    "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
    "                train_loss_list.append(average_train_loss)\n",
    "                valid_loss_list.append(average_valid_loss)\n",
    "                global_steps_list.append(global_step)\n",
    "                \n",
    "                running_loss = 0.0\n",
    "                valid_running_loss = 0.0\n",
    "                model.train()\n",
    "                \n",
    "                print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{global_step}/{num_epochs * len(train_loader)}], Train Loss: {average_train_loss : .4f}, Valid Loss: {average_valid_loss : .4f}\")\n",
    "                \n",
    "                if best_valid_loss > average_valid_loss:\n",
    "                    best_valid_loss = average_valid_loss\n",
    "                    save_checkpoint(\"../pytorch/data/model.pt\", model, best_valid_loss)\n",
    "                    save_metrics(\"../pytorch/data/metrics.pt\", train_loss_list, valid_loss_list, global_steps_list)\n",
    "    save_metrics(\"../pytorch/data/metrics.pt\", train_loss_list, valid_loss_list, global_steps_list)\n",
    "    print(\"훈련 종료!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T05:38:56.293211300Z",
     "start_time": "2023-09-27T05:38:56.288709200Z"
    }
   },
   "id": "d6d2ab219f8b524"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amil0\\AppData\\Local\\Temp\\ipykernel_16528\\1228514097.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(label)\n",
      "C:\\Users\\amil0\\AppData\\Local\\Temp\\ipykernel_16528\\1228514097.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred = torch.argmax(F.softmax(logits), dim=1)\n",
      "C:\\Users\\amil0\\AppData\\Local\\Temp\\ipykernel_16528\\1228514097.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [510/5100], Train Loss:  0.7161, Valid Loss:  0.7060\n",
      "Model saved to ==> ../pytorch/data/model.pt\n",
      "Model saved to ==> ../pytorch/data/metrics.pt\n",
      "Epoch [1/5], Step [1020/5100], Train Loss:  0.7078, Valid Loss:  0.6956\n",
      "Model saved to ==> ../pytorch/data/model.pt\n",
      "Model saved to ==> ../pytorch/data/metrics.pt\n",
      "Epoch [2/5], Step [1530/5100], Train Loss:  0.7054, Valid Loss:  0.7052\n",
      "Epoch [2/5], Step [2040/5100], Train Loss:  0.7033, Valid Loss:  0.7122\n",
      "Epoch [3/5], Step [2550/5100], Train Loss:  0.7042, Valid Loss:  0.6949\n",
      "Model saved to ==> ../pytorch/data/model.pt\n",
      "Model saved to ==> ../pytorch/data/metrics.pt\n",
      "Epoch [3/5], Step [3060/5100], Train Loss:  0.7028, Valid Loss:  0.6944\n",
      "Model saved to ==> ../pytorch/data/model.pt\n",
      "Model saved to ==> ../pytorch/data/metrics.pt\n",
      "Epoch [4/5], Step [3570/5100], Train Loss:  0.7102, Valid Loss:  0.6938\n",
      "Model saved to ==> ../pytorch/data/model.pt\n",
      "Model saved to ==> ../pytorch/data/metrics.pt\n",
      "Epoch [4/5], Step [4080/5100], Train Loss:  0.7013, Valid Loss:  0.6931\n",
      "Model saved to ==> ../pytorch/data/model.pt\n",
      "Model saved to ==> ../pytorch/data/metrics.pt\n",
      "Epoch [5/5], Step [4590/5100], Train Loss:  0.7075, Valid Loss:  0.6991\n",
      "Epoch [5/5], Step [5100/5100], Train Loss:  0.7075, Valid Loss:  0.7013\n",
      "Model saved to ==> ../pytorch/data/metrics.pt\n",
      "훈련 종료!\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "train(model=model, optimizer=optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T06:03:15.994135900Z",
     "start_time": "2023-09-27T05:38:56.294345600Z"
    }
   },
   "id": "ee75059f231be719"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== ../pytorch/data/metrics.pt\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'global_steps_list'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m train_loss_list, valid_loss_list, global_steps_list \u001B[38;5;241m=\u001B[39m load_metrics(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../pytorch/data/metrics.pt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(global_steps_list, train_loss_list, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrain\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      4\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(global_steps_list, valid_loss_list, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mValid\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[26], line 30\u001B[0m, in \u001B[0;36mload_metrics\u001B[1;34m(load_path)\u001B[0m\n\u001B[0;32m     28\u001B[0m state_dict \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mload(load_path, map_location\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel loaded from <== \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mload_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 30\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m state_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_loss_list\u001B[39m\u001B[38;5;124m\"\u001B[39m], state_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalid_loss_list\u001B[39m\u001B[38;5;124m\"\u001B[39m], state_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mglobal_steps_list\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "\u001B[1;31mKeyError\u001B[0m: 'global_steps_list'"
     ]
    }
   ],
   "source": [
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics(\"../pytorch/data/metrics.pt\")\n",
    "\n",
    "plt.plot(global_steps_list, train_loss_list, label=\"Train\")\n",
    "plt.plot(global_steps_list, valid_loss_list, label=\"Valid\")\n",
    "plt.xlabel(\"Global Steps\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T06:03:16.025319Z",
     "start_time": "2023-09-27T06:03:15.988118200Z"
    }
   },
   "id": "2da0886d15a0fd16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for text, label in test_loader:\n",
    "            encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "            padded_list = [e + [0] * (512 - len(e)) for e in encoded_list]\n",
    "            sample = torch.tensor(padded_list)\n",
    "            sample, label = sample.to(device), label.to(device)\n",
    "            labels = torch.tensor(label)\n",
    "            output = model(sample, labels=labels)\n",
    "            _, output = output\n",
    "            y_pred.extend(torch.argmax(output, 1).tolist())\n",
    "            y_true.extend(labels.tolist())\n",
    "            \n",
    "    print(\"Classification 결과:\")\n",
    "    print(classification_report(y_true, y_pred, labels=[1, 0], digits=4))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1, 0])\n",
    "    ax = plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax=ax, cmap=\"Blues\", fmt=\"d\")\n",
    "    ax.set_title(\"Confusion Matrix\")\n",
    "    ax.set_xlabel(\"Predicted Labels\")\n",
    "    ax.set_ylabel(\"True Labels\")\n",
    "    ax.xaxis.set_ticklabels([\"0\", \"1\"])\n",
    "    ax.yaxis.set_ticklabels([\"0\", \"1\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-27T06:03:16.021046700Z"
    }
   },
   "id": "e3ad756ece1ce870"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_model = model.to(device)\n",
    "load_checkpoint(\"../pytorch/data/model.pt\", best_model)\n",
    "evaluate(best_model, test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-27T06:03:16.023320700Z"
    }
   },
   "id": "7cc2fc139eb65c27"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

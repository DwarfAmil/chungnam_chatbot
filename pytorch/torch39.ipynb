{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-27T06:32:57.018119300Z",
     "start_time": "2023-09-27T06:32:56.030099400Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '나는', '파', '##이', '##토', '##치를', '이', '##용한', '딥', '##러', '##닝', '##을', '학', '##습', '##중', '##이다', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "text = \"나는 파이토치를 이용한 딥러닝을 학습중이다.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "print(tokenized_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T06:32:57.025375Z",
     "start_time": "2023-09-27T06:32:57.021652900Z"
    }
   },
   "id": "2d848a865315b1f5"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           101\n",
      "과             8,898\n",
      "##수          15,891\n",
      "##원에         108,280\n",
      "사             9,405\n",
      "##과          11,882\n",
      "##가          11,287\n",
      "많             9,249\n",
      "##았다         27,303\n",
      ".               119\n",
      "친             9,781\n",
      "##구          17,196\n",
      "##가          11,287\n",
      "나             8,982\n",
      "##에게         26,212\n",
      "사             9,405\n",
      "##과          11,882\n",
      "##했다         12,490\n",
      ".               119\n",
      "백             9,331\n",
      "##설          31,928\n",
      "##공          28,000\n",
      "##주는         100,633\n",
      "독             9,088\n",
      "##이          10,739\n",
      "든             9,115\n",
      "사             9,405\n",
      "##과          11,882\n",
      "##를          11,513\n",
      "먹             9,266\n",
      "##었다         17,706\n",
      ".               119\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "text = \"과수원에 사과가 많았다.\" \\\n",
    "    \"친구가 나에게 사과했다.\" \\\n",
    "    \"백설공주는 독이 든 사과를 먹었다.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print(f\"{tup[0] : <12} {tup[1] : >6,}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T06:32:57.042119300Z",
     "start_time": "2023-09-27T06:32:57.024231100Z"
    }
   },
   "id": "84b980dfc4705535"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "segments_ids = [1] * len(tokenized_text)\n",
    "print(segments_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T06:32:57.044650700Z",
     "start_time": "2023-09-27T06:32:57.040709500Z"
    }
   },
   "id": "93a43cccbcbe2a6"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T06:32:57.055191100Z",
     "start_time": "2023-09-27T06:32:57.044650700Z"
    }
   },
   "id": "874add61db045bce"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "BertModel(\n  (embeddings): BertEmbeddings(\n    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n    (position_embeddings): Embedding(512, 768)\n    (token_type_embeddings): Embedding(2, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): BertEncoder(\n    (layer): ModuleList(\n      (0-11): 12 x BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): BertPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertModel.from_pretrained(\"bert-base-multilingual-cased\", output_hidden_states=True)\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T06:33:00.565567Z",
     "start_time": "2023-09-27T06:32:57.049564100Z"
    }
   },
   "id": "403727f5bd471a1d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**모델 적용**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a80cf4bb6981414"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "    hidden_states = outputs[2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T06:33:00.628841500Z",
     "start_time": "2023-09-27T06:33:00.566574Z"
    }
   },
   "id": "253a04949c014a10"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "계층 개수: 13  (initial embeddings + 12 BERT layers)\n",
      "배치 개수: 1\n",
      "토큰 개수: 33\n",
      "은닉층의 유닛 개수 768\n"
     ]
    }
   ],
   "source": [
    "print(\"계층 개수:\", len(hidden_states), \" (initial embeddings + 12 BERT layers)\")\n",
    "layer_i = 0\n",
    "print(\"배치 개수:\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "print(\"토큰 개수:\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "print(\"은닉층의 유닛 개수\", len(hidden_states[layer_i][batch_i][token_i]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T06:33:00.630847400Z",
     "start_time": "2023-09-27T06:33:00.627404900Z"
    }
   },
   "id": "cd30cf010b810f12"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "은닉 상태의 유형:  <class 'tuple'>\n",
      "각 계층에서의 텐서 형태:  torch.Size([1, 33, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"은닉 상태의 유형: \", type(hidden_states))\n",
    "print(\"각 계층에서의 텐서 형태: \", hidden_states[0].size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T06:33:00.640358900Z",
     "start_time": "2023-09-27T06:33:00.630847400Z"
    }
   },
   "id": "7c4a5e37ac538f2"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([13, 1, 33, 768])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "token_embeddings.size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T06:33:00.661977100Z",
     "start_time": "2023-09-27T06:33:00.636359200Z"
    }
   },
   "id": "a8fcda866cdd4ac5"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([13, 33, 768])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "token_embeddings.size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T06:33:00.698371300Z",
     "start_time": "2023-09-27T06:33:00.646223300Z"
    }
   },
   "id": "99343e0a90c4b244"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([33, 13, 768])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = token_embeddings.permute(1, 0, 2)\n",
    "token_embeddings.size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T06:33:00.698371300Z",
     "start_time": "2023-09-27T06:33:00.658716500Z"
    }
   },
   "id": "ebb77101738b1f8b"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "형태는:  33 x  3072\n"
     ]
    }
   ],
   "source": [
    "token_vecs_cat = []\n",
    "for token in token_embeddings:\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    token_vecs_cat.append(cat_vec)\n",
    "print(f\"형태는: {len(token_vecs_cat) : d} x {len(token_vecs_cat[0]) : d}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T06:33:00.712781700Z",
     "start_time": "2023-09-27T06:33:00.661977100Z"
    }
   },
   "id": "2b4cd4b2a3961135"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "형태는:  33 x  768\n"
     ]
    }
   ],
   "source": [
    "token_vecs_sum = []\n",
    "for token in token_embeddings:\n",
    "    sum_vec = torch.sum(token[-4:], dim=0)\n",
    "    token_vecs_sum.append(sum_vec)\n",
    "print(f\"형태는: {len(token_vecs_sum) : d} x {len(token_vecs_sum[0]) : d}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T06:33:00.713289500Z",
     "start_time": "2023-09-27T06:33:00.671661400Z"
    }
   },
   "id": "a1a11ca88144828"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 임베딩 벡터의 형태: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "token_vecs = hidden_states[-2][0]\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "print(\"최종 임베딩 벡터의 형태:\", sentence_embedding.size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T06:33:00.713289500Z",
     "start_time": "2023-09-27T06:33:00.678818900Z"
    }
   },
   "id": "83dd6a09fd413495"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS]\n",
      "1 과\n",
      "2 ##수\n",
      "3 ##원에\n",
      "4 사\n",
      "5 ##과\n",
      "6 ##가\n",
      "7 많\n",
      "8 ##았다\n",
      "9 .\n",
      "10 친\n",
      "11 ##구\n",
      "12 ##가\n",
      "13 나\n",
      "14 ##에게\n",
      "15 사\n",
      "16 ##과\n",
      "17 ##했다\n",
      "18 .\n",
      "19 백\n",
      "20 ##설\n",
      "21 ##공\n",
      "22 ##주는\n",
      "23 독\n",
      "24 ##이\n",
      "25 든\n",
      "26 사\n",
      "27 ##과\n",
      "28 ##를\n",
      "29 먹\n",
      "30 ##었다\n",
      "31 .\n",
      "32 [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i, token_str in enumerate(tokenized_text):\n",
    "    print(i, token_str)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T06:33:00.714779200Z",
     "start_time": "2023-09-27T06:33:00.690753100Z"
    }
   },
   "id": "7a24fc4a66aa75a2"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사과가 많았다 tensor([-0.5844, -4.0836,  0.4906,  0.8915, -1.8054])\n",
      "나에게 사과했다 tensor([-0.8631, -3.4047, -0.7351,  0.9805, -2.6700])\n",
      "사과를 먹었다 tensor([ 0.6756, -0.3618,  0.0586,  2.2050, -2.4193])\n"
     ]
    }
   ],
   "source": [
    "print(\"사과가 많았다\", str(token_vecs_sum[6][:5]))\n",
    "print(\"나에게 사과했다\", str(token_vecs_sum[10][:5]))\n",
    "print(\"사과를 먹었다\", str(token_vecs_sum[19][:5]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T06:33:00.726592900Z",
     "start_time": "2023-09-27T06:33:00.694514700Z"
    }
   },
   "id": "9ce5597a1b56a21e"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*유사한* 의미에 대한 벡터 유사성:  0.86\n",
      "*다른* 의미에 대한 벡터 유사성:  0.91\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "diff_apple = 1 - cosine(token_vecs_sum[5], token_vecs_sum[27])\n",
    "same_apple = 1 - cosine(token_vecs_sum[5], token_vecs_sum[16])\n",
    "print(f\"*유사한* 의미에 대한 벡터 유사성: {same_apple : .2f}\")\n",
    "print(f\"*다른* 의미에 대한 벡터 유사성: {diff_apple : .2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T06:33:00.727593700Z",
     "start_time": "2023-09-27T06:33:00.705551300Z"
    }
   },
   "id": "8cecac5defc87e57"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
